{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5  color=#003366> <b>[LEPL1109] - STATISTICS AND DATA SCIENCES</b> <br><br> \n",
    "<b>Hackathon 03 - Clustering: Bias in sensitive datasets</b> </font> <br><br><br>\n",
    "\n",
    "<font size=4  color=#003366>\n",
    "Prof. D. Hainaut<br>\n",
    "Prof. L. Jacques<br>\n",
    "\n",
    "<br><br>\n",
    "Adrien Banse (adrien.banse@uclouvain.be)<br>\n",
    "Jana Jovcheva (jana.jovcheva@uclouvain.be)<br>\n",
    "François Lessage (francois.lessage@uclouvain.be)<br>\n",
    "Sofiane Tanji (sofiane.tanji@uclouvain.be)<br>\n",
    "<div style=\"text-align: right\"> Version 2024-2025</div>\n",
    "<br><br>\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>[IMPORTANT] Read all the documentation</b>  <br>\n",
    "    Make sure that you read the whole notebook, <b>and</b> the <code>README.md</code> file in the folder.\n",
    "</div>\n",
    "<br><br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Guidelines and Deliverables**\n",
    "\n",
    "*   This hackathon is due on the **22 December 2024 at 22h00**\n",
    "*   Copying code or answers from other groups (or from the internet) is strictly forbidden. <b>Each source of inspiration (stack overflow, git, other groups, ChatGPT...) must be clearly indicated!</b>\n",
    "*  This notebook (with the \"ipynb\" extension) file, the report (PDF format) and all other files that are necessary to run your code must be delivered on <b>Moodle</b>.\n",
    "* Only the PDF report and the python source file will be graded, both on their content and the quality of the text / figures.\n",
    "  * 5/10 for the code.\n",
    "  * 4/10 for the Latex report.\n",
    "  * 1/10 for the visualization. <br><br>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>[DELIVERABLE] Summary</b>  <br>\n",
    "After the reading of this document (and playing with the code!), we expect you to provide us with:\n",
    "<ol>\n",
    "   <li> a PDF file (written in LaTeX) that answers all the questions below. The report should contain high quality figures with named axes (we recommend saving plots with the <samp>.pdf</samp> extension);\n",
    "   <li> this Jupyter Notebook (it will be read, checked for plagiarism and evaluated);\n",
    "   <li> and all other files we would need to run your code.\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "As mentioned above, plagiarism is forbidden. However, we cannot forbid you to use artificial intelligence BUT we remind you that the aim of this project is to learn on your own and with the help of the course material. Finally, we remind you that for the same question, artificial intelligence presents similar solutions, which could be perceived as a form of plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Context & Objective**\n",
    "\n",
    "## Context\n",
    "\n",
    "Predictive algorithms serve multiple functions in criminal justice. They forecast crime locations, identify potential violent offenders, predict court appearance compliance, and estimate recidivism risk. \n",
    "COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) stands as a prominent risk assessment tool. Since 1998, the COMPAS risk score has been used by many jurisdictions in the United States to assess risk of recidivism in pre-trial bail decisions.\n",
    "In the United States, a defendant may either be detained or released on bail *(sous caution)* prior to the trial in court depending on various factors. Judges may detain defendants or increase the bail amount based on the risk score provided by the COMPAS algorithm.\n",
    "\n",
    "\n",
    "In 2016, investigative journalists at ProPublica published [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing), highlighting significant biases in the COMPAS Algorithm. Specifically, they showed that the proportion of false positives for African-American defendants is significantly higher than for Caucasian defendants. In other words, more African-American were labeled high risk and ended up not relapsing into criminal behaviour than Caucasian defendants. A more thorough explanation of their data analysis procedure can be found in their companion article [How We Analyzed the COMPAS Recidivism Algorithm](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm).\n",
    "\n",
    "The COMPAS algorithm is proprietary software. What is known is that its decision is based on the answers to a questionnaire with 137 questions which the defendant must fill. There are questions related to crime (“How many prior juvenile felony offense arrests?”) along with seemingly mundane ones (“Do you live with friends?”; “Do you feel discouraged at times?”).\n",
    "\n",
    "In this hackathon, you are provided a dataset with a subset of answers to that questionnaire from more than 7000 defendants living in Broward County, Florida as well as whether they did relapse into criminal behaviour or not.\n",
    "\n",
    "## Objective(s)\n",
    "It has been shown in the article linked above that the COMPAS algorithm is biased. We take this for granted and we do not bother to show it again. The main objective of the hackathon for you is to understand that it is not only the COMPAS algorithm that is biased, but that **the data itself is biased**, in the sense that one can find structural patterns of discrimination embedded in the data. In other words, *learning from data coming from a biased world without precautions will necessarily lead to biased predictions*. Knowing which precautions one should take to avoid biased predictions is a whole subfield of machine learning called \"Fairness in AI\". It is out of the scope of this hackathon and out of the scope of LEPL1109. If you are curious about it however, a great resource is the following book [Fairness and machine learning Limitations and Opportunities](https://fairmlbook.org/).\n",
    "\n",
    "To see that the data itself is biased, you will implement your own recidivism prediction algorithms and measure their fairness.\n",
    "\n",
    "## Dataset description\n",
    "A large part of this hackathon will be devoted to handling, understanding and manipulating the dataset. The dataset provided represents 7214 defendants (data points) with 49 answers to the questionnaire (features) for each defendant. This is a lot of features and it should take you some time to understand them before going through Part 1. This data processing part may be tiresome but it is a necessary task in any serious data project.\n",
    "A description of the features is provided in the table below:\n",
    "\n",
    "| Feature               | Description                                                                                      |\n",
    "|-----------------------|--------------------------------------------------------------------------------------------------|\n",
    "| name                  | Full name of the defendant                                                                       |\n",
    "| first                 | First name of the defendant                                                                      |\n",
    "| last                  | Last name of the defendant                                                                       |\n",
    "| compas_screening_date | The date the defendant filled the questionnaire                                                  |\n",
    "| sex                   | Sex of the defendant (Female, Male)                                                              |\n",
    "| dob                   | Date of birth of the defendant (YYYY-MM-DD)                                                      |\n",
    "| age                   | Age of the defendant                                                                             |\n",
    "| age_cat               | Age category of the defendant (Less than 25, 25-45, Greater than 45)                             |\n",
    "| race                  | race attribute (African-American, Caucasian, Hispanic, Asian, Native American, Other)       |\n",
    "| juv_fel_count         | Number of juvenile felonies committed by the defendant                                           |\n",
    "| decile_score          | Decile of the COMPAS score                                                                       |\n",
    "| juv_misd_count        | Number of juvenile misdemeanors                                                                  |\n",
    "| juv_other_count       | Number of juvenile convictions that are not considered misdemeanors nor felonies                 |\n",
    "| priors_count          | Number of prior crimes committed                                                                 |\n",
    "| days_b_screening_arrest | Count of days between screening date and (original) arrest date                                |\n",
    "| c_jail_in             | Datetime at which the defendant entered jail (YYYY-MM-DD, hh:mm:ss)                              |\n",
    "| c_jail_out            | Datetime at which the defendant left jail (YYYY-MM-DD, hh:mm:ss)                                 |\n",
    "| c_case_number         | Case number for the current charge                                                               |\n",
    "| c_offense_date        | Date the offense was committed (YYYY-MM-DD)                                                      |\n",
    "| c_arrest_date         | Date the offense was arrested (YYYY-MM-DD)                                                       |\n",
    "| c_days_from_compas    | Days from COMPAS screening date to current arrest date                                           |\n",
    "| c_charge_degree       | Current charge degree (felony or misdemeanor) at the time of filling the questionnaire (\"F\", \"M\")|\n",
    "| c_charge_desc         | Description of the current charge                                                                |\n",
    "| is_recid              | Binary variable indicating whether the defendant is rearrested at any time (0, 1)                |\n",
    "| r_case_number         | Case number for a recidivism charge                                                              |\n",
    "| r_charge_degree       | Recidivism charge degree (felony or misdemeanor) for an offense subsequent to filling the questionnaire |\n",
    "| r_days_from_arrest    | Days from Arrest to Recidivism Event                                                             |\n",
    "| r_offense_date        | Date the recidivism offense was committed (YYYY-MM-DD)                                           |\n",
    "| r_charge_desc         | Description of the recidivism charge                                                             |\n",
    "| r_jail_in             | Datetime at which the defendant entered jail for a recidivism charge (YYYY-MM-DD, hh:mm:ss)      |\n",
    "| r_jail_out            | Datetime at which the defendant left jail for a recidivism charge (YYYY-MM-DD, hh:mm:ss)         |\n",
    "| violent_recid         | Number of violent recidivism events                                                              |\n",
    "| is_violent_recid      | Binary variable indicating whether the defendant committed a violent recidivism (0, 1)           |\n",
    "| vr_case_number        | Case number for a violent recidivism charge                                                      |\n",
    "| vr_charge_degree      | Violent recidivism charge degree (felony or misdemeanor)                                         |\n",
    "| vr_offense_date       | Date the violent recidivism offense was committed (YYYY-MM-DD)                                   |\n",
    "| vr_charge_desc        | Description of the violent recidivism charge                                                     |\n",
    "| type_of_assessment    | Type of COMPAS assessment performed                                                              |\n",
    "| decile_score.1        | *Same as decile_score*                                                                           |\n",
    "| score_text            | Recidivism risk of the defendant (Low, Medium, High)                                             |\n",
    "| screening_date        | Date on which the defendant was screened (YYYY-MM-DD)                                            |\n",
    "| v_type_of_assessment  | Type of violent risk assessment                                                                  |\n",
    "| v_decile_score        | Decile score for violent risk assessment                                                         |\n",
    "| v_score_text          | Violent recidivism risk of the defendant (Low, Medium, High)                                     |\n",
    "| v_screening_date      | Date of the violent risk assessment (YYYY-MM-DD)                                                 |\n",
    "| in_custody            | Date on which the defendant was placed in custody (YYYY-MM-DD)                                   |\n",
    "| out_custody           | Date on which the defendant left custody (YYYY-MM-DD)                                            |\n",
    "| priors_count.1        | *Same as priors_count*                                                                           |\n",
    "| two_year_recid        | Binary variable on whether the defendant has recidivated within two years (0, 1)                 |\n",
    "\n",
    "## **Notebook structure**\n",
    "\n",
    "### PART 1 - Data preprocessing\n",
    "   #### 1.1 - Importing the packages\n",
    "   #### 1.2 - Importing the dataset\n",
    "   #### 1.3 - Dataset curation\n",
    "   #### 1.4 - Feature engineering\n",
    "   #### 1.5 - Sensitive features\n",
    "   #### 1.6 - Scale the dataset\n",
    "\n",
    "### PART 2 - Data exploration\n",
    "   #### 2.1 - Feature visualization\n",
    "   #### 2.2 - Principal Component Analysis\n",
    "\n",
    "   \n",
    "### PART 3 - Clustering\n",
    "   #### 3.1 - K-Means\n",
    "   #### 3.2 - Results Analysis\n",
    "\n",
    "\n",
    "### PART 4 - Validation and fairness metrics\n",
    "   #### 4.1 - Silhouette score\n",
    "   #### 4.2 - Purity and entropy of a clustering\n",
    "   #### 4.3 - Precision and Recall per race group\n",
    "   #### 4.4 - Select the number of clusters\n",
    "\n",
    "\n",
    "### PART 5 - Visualization\n",
    "   #### 5.1 - Visualize your results\n",
    "\n",
    "<br><br>\n",
    "\n",
    "***Remark***\n",
    "\n",
    "We filled this notebook with preliminary (trivial) code. This practice makes possible to run each cell, even the last ones, without throwing warnings once the dataset is imported. <b>Take advantage of this aspect to divide the work between all team members!</b> <br><br>\n",
    "Remember that many libraries exist in Python, so many functions have already been developed. Read the documentation and don't reinvent the wheel! You can import whatever you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=7 color=#009999> <b>PART I - Preliminaries</b> </font> <br><br>\n",
    "\n",
    "<font size=5 color=#009999> <b>1.1 - Importing the packages</b> <br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL N°1.1 : IMPORTING ALL THE NECESSARY PACKAGES\n",
    "\n",
    "@pre:  /\n",
    "@post: The necessary packages should be loaded.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import all the necessary packages here...\n",
    "from pandas.api.types import is_numeric_dtype, is_object_dtype\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>1.2 - Importing the dataset</b> <br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7214 entries, 0 to 7213\n",
      "Data columns (total 49 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   name                     7214 non-null   object \n",
      " 1   first                    7214 non-null   object \n",
      " 2   last                     7214 non-null   object \n",
      " 3   compas_screening_date    7214 non-null   object \n",
      " 4   sex                      7214 non-null   object \n",
      " 5   dob                      7214 non-null   object \n",
      " 6   age                      7214 non-null   int64  \n",
      " 7   age_cat                  7214 non-null   object \n",
      " 8   race                     7214 non-null   object \n",
      " 9   juv_fel_count            7214 non-null   int64  \n",
      " 10  decile_score             7214 non-null   int64  \n",
      " 11  juv_misd_count           7214 non-null   int64  \n",
      " 12  juv_other_count          7214 non-null   int64  \n",
      " 13  priors_count             7214 non-null   int64  \n",
      " 14  days_b_screening_arrest  6907 non-null   float64\n",
      " 15  c_jail_in                6907 non-null   object \n",
      " 16  c_jail_out               6907 non-null   object \n",
      " 17  c_case_number            7192 non-null   object \n",
      " 18  c_offense_date           6055 non-null   object \n",
      " 19  c_arrest_date            1137 non-null   object \n",
      " 20  c_days_from_compas       7192 non-null   float64\n",
      " 21  c_charge_degree          7214 non-null   object \n",
      " 22  c_charge_desc            7185 non-null   object \n",
      " 23  is_recid                 7214 non-null   int64  \n",
      " 24  r_case_number            3471 non-null   object \n",
      " 25  r_charge_degree          3471 non-null   object \n",
      " 26  r_days_from_arrest       2316 non-null   float64\n",
      " 27  r_offense_date           3471 non-null   object \n",
      " 28  r_charge_desc            3413 non-null   object \n",
      " 29  r_jail_in                2316 non-null   object \n",
      " 30  r_jail_out               2316 non-null   object \n",
      " 31  violent_recid            0 non-null      float64\n",
      " 32  is_violent_recid         7214 non-null   int64  \n",
      " 33  vr_case_number           819 non-null    object \n",
      " 34  vr_charge_degree         819 non-null    object \n",
      " 35  vr_offense_date          819 non-null    object \n",
      " 36  vr_charge_desc           819 non-null    object \n",
      " 37  type_of_assessment       7214 non-null   object \n",
      " 38  decile_score.1           7214 non-null   int64  \n",
      " 39  score_text               7214 non-null   object \n",
      " 40  screening_date           7214 non-null   object \n",
      " 41  v_type_of_assessment     7214 non-null   object \n",
      " 42  v_decile_score           7214 non-null   int64  \n",
      " 43  v_score_text             7214 non-null   object \n",
      " 44  v_screening_date         7214 non-null   object \n",
      " 45  in_custody               6978 non-null   object \n",
      " 46  out_custody              6978 non-null   object \n",
      " 47  priors_count.1           7214 non-null   int64  \n",
      " 48  two_year_recid           7214 non-null   int64  \n",
      "dtypes: float64(4), int64(12), object(33)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°1.2 : IMPORTING THE DATASET\n",
    "\n",
    "@pre:  /\n",
    "@post: The object `df` should contain a Pandas DataFrame corresponding to the file `compas-dataset.csv`.\n",
    "\"\"\"\n",
    "\n",
    "df= pd.read_csv(\"compas-dataset.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>1.3 - Dataset curation</b> <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this hackathon, your goal is to **determine the risk of recidivism of an individual**. Therefore, you should be able to determine which features are useful for your application and remove the unnecessary ones. We provide a list of features to keep and ask you to add features to that list. This step may take more time than the others. It is important to carefully analyze each feature and its relevance for our goal.\n",
    "\n",
    "In this data cleaning task, you must remove redundant features, features that are not quantifiable and features that you believe are not linked to risk of recidivism. Yous should neither limit yourself to the provided list which is too short nor add all numeric features.\n",
    "You should also avoid data leakage. Except for the \"two_year_recid\" feature, do not keep features which represent true recidivism. For similar reasons, do not keep features linked to the predictions made by the COMPAS algorithm. Using predictions made by a supervised algorithm (which is trained using both the features matrix and the target variable) is effectively leaking information from the target variable.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 1.1] Removing unnecessary features </b>  <br>\n",
    "Can you already, a priori, detect that some features are useless?\n",
    "<ol>\n",
    "   <li> if yes, list those (useless) features and explain your choice;\n",
    "   <li> if not, then explain why it is better to wait.\n",
    "</ol>\n",
    "    Generally speaking, is it a good idea to remove a feature based on <i>a priori</i> knowledge, or doesn't it alter the final outcome?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6172 entries, 0 to 7213\n",
      "Data columns (total 36 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   sex                      6172 non-null   object \n",
      " 1   race                     6172 non-null   object \n",
      " 2   c_jail_in                6172 non-null   object \n",
      " 3   c_jail_out               6172 non-null   object \n",
      " 4   in_custody               6172 non-null   object \n",
      " 5   out_custody              6172 non-null   object \n",
      " 6   two_year_recid           6172 non-null   int64  \n",
      " 7   juv_fel_count            6172 non-null   int64  \n",
      " 8   decile_score             6172 non-null   int64  \n",
      " 9   juv_misd_count           6172 non-null   int64  \n",
      " 10  juv_other_count          6172 non-null   int64  \n",
      " 11  priors_count             6172 non-null   int64  \n",
      " 12  c_offense_date           5388 non-null   object \n",
      " 13  c_arrest_date            784 non-null    object \n",
      " 14  c_charge_degree          6172 non-null   object \n",
      " 15  is_recid                 6172 non-null   int64  \n",
      " 16  r_charge_degree          2990 non-null   object \n",
      " 17  r_days_from_arrest       1997 non-null   float64\n",
      " 18  r_offense_date           2990 non-null   object \n",
      " 19  r_charge_desc            2944 non-null   object \n",
      " 20  r_jail_in                1997 non-null   object \n",
      " 21  r_jail_out               1997 non-null   object \n",
      " 22  violent_recid            0 non-null      float64\n",
      " 23  is_violent_recid         6172 non-null   int64  \n",
      " 24  vr_charge_degree         692 non-null    object \n",
      " 25  vr_offense_date          692 non-null    object \n",
      " 26  type_of_assessment       6172 non-null   object \n",
      " 27  decile_score.1           6172 non-null   int64  \n",
      " 28  score_text               6172 non-null   object \n",
      " 29  screening_date           6172 non-null   object \n",
      " 30  v_type_of_assessment     6172 non-null   object \n",
      " 31  decile_score             6172 non-null   int64  \n",
      " 32  v_score_text             6172 non-null   object \n",
      " 33  v_screening_date         6172 non-null   object \n",
      " 34  priors_count.1           6172 non-null   int64  \n",
      " 35  days_b_screening_arrest  6172 non-null   float64\n",
      "dtypes: float64(3), int64(11), object(22)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°1.3.1 : CURATION OF THE DATASET\n",
    "\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset\n",
    "@post: A pandas.DataFrame `df` containing the dataset without outliers and with necessary features only\n",
    "\"\"\"\n",
    "\n",
    "# Remove outliers based on the defined criteria\n",
    "df = df[\n",
    "    (\n",
    "        df[\"is_recid\"] != -1  # Filter out rows with invalid is_recid\n",
    "    )\n",
    "    & (\n",
    "        df[\"days_b_screening_arrest\"] <= 30  # Retain rows with screening within 30 days of arrest\n",
    "    )\n",
    "    & (df[\"days_b_screening_arrest\"] >= -30)  # Retain rows with screening within 30 days before arrest\n",
    "    & (\n",
    "        df[\"c_charge_degree\"] != \"O\"  # Exclude rows with simple traffic offenses\n",
    "    )\n",
    "]\n",
    "\n",
    "# Ensure the necessary columns are retained\n",
    "columns_to_keep = [\n",
    "    \"sex\",\n",
    "    \"race\",\n",
    "    \"c_jail_in\",\n",
    "    \"c_jail_out\",\n",
    "    \"in_custody\",\n",
    "    \"out_custody\",\n",
    "    \"two_year_recid\",\n",
    "    \"juv_fel_count\",\n",
    "    \"decile_score\",\n",
    "    \"juv_misd_count\",\n",
    "    \"juv_other_count\",\n",
    "    \"priors_count\", \n",
    "    \"c_offense_date\",\n",
    "    \"c_arrest_date\",\n",
    "    \"c_charge_degree\",\n",
    "    \"is_recid\",\n",
    "    \"r_charge_degree\",\n",
    "    \"r_days_from_arrest\",\n",
    "    \"r_offense_date\",\n",
    "    \"r_charge_desc\",\n",
    "    \"r_jail_in\",\n",
    "    \"r_jail_out\",\n",
    "    \"violent_recid\",\n",
    "    \"is_violent_recid\",\n",
    "    \"vr_charge_degree\",\n",
    "    \"vr_offense_date\",\n",
    "    \"type_of_assessment\",\n",
    "    \"decile_score.1\",\n",
    "    \"score_text\",\n",
    "    \"screening_date\",\n",
    "    \"v_type_of_assessment\",\n",
    "    \"decile_score\",\n",
    "    \"v_score_text\",\n",
    "    \"v_screening_date\",\n",
    "    \"priors_count.1\",\n",
    "    \"days_b_screening_arrest\"\n",
    "]\n",
    "\n",
    "# Keep only the specified columns, ensuring they exist in the DataFrame\n",
    "columns_to_keep = [col for col in columns_to_keep if col in df.columns]\n",
    "df = df.loc[:, columns_to_keep]\n",
    "\n",
    "# Display the DataFrame info\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data science, datasets are rarely tailored to specific applications. Instead, they typically originate from information collected over a certain period. It is the data scientist's responsibility to effectively utilize these datasets.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>[Remark 1.1]</b><br>\n",
    "In most real-world cases, the datasets you work with will contain artifacts like typos or missing data, which may need to be removed before using them in algorithms. In Pandas, missing data is represented as \"NaNs\" (Not a Number), though it applies to all missing objects, not just numbers.\n",
    "</div>\n",
    "\n",
    "Can you find a way to inspect your dataset and see if there are some missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types and Non-Null Counts:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6172 entries, 0 to 7213\n",
      "Data columns (total 36 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   sex                      6172 non-null   object \n",
      " 1   race                     6172 non-null   object \n",
      " 2   c_jail_in                6172 non-null   object \n",
      " 3   c_jail_out               6172 non-null   object \n",
      " 4   in_custody               6172 non-null   object \n",
      " 5   out_custody              6172 non-null   object \n",
      " 6   two_year_recid           6172 non-null   int64  \n",
      " 7   juv_fel_count            6172 non-null   int64  \n",
      " 8   decile_score             6172 non-null   int64  \n",
      " 9   juv_misd_count           6172 non-null   int64  \n",
      " 10  juv_other_count          6172 non-null   int64  \n",
      " 11  priors_count             6172 non-null   int64  \n",
      " 12  c_offense_date           5388 non-null   object \n",
      " 13  c_arrest_date            784 non-null    object \n",
      " 14  c_charge_degree          6172 non-null   object \n",
      " 15  is_recid                 6172 non-null   int64  \n",
      " 16  r_charge_degree          2990 non-null   object \n",
      " 17  r_days_from_arrest       1997 non-null   float64\n",
      " 18  r_offense_date           2990 non-null   object \n",
      " 19  r_charge_desc            2944 non-null   object \n",
      " 20  r_jail_in                1997 non-null   object \n",
      " 21  r_jail_out               1997 non-null   object \n",
      " 22  violent_recid            0 non-null      float64\n",
      " 23  is_violent_recid         6172 non-null   int64  \n",
      " 24  vr_charge_degree         692 non-null    object \n",
      " 25  vr_offense_date          692 non-null    object \n",
      " 26  type_of_assessment       6172 non-null   object \n",
      " 27  decile_score.1           6172 non-null   int64  \n",
      " 28  score_text               6172 non-null   object \n",
      " 29  screening_date           6172 non-null   object \n",
      " 30  v_type_of_assessment     6172 non-null   object \n",
      " 31  decile_score             6172 non-null   int64  \n",
      " 32  v_score_text             6172 non-null   object \n",
      " 33  v_screening_date         6172 non-null   object \n",
      " 34  priors_count.1           6172 non-null   int64  \n",
      " 35  days_b_screening_arrest  6172 non-null   float64\n",
      "dtypes: float64(3), int64(11), object(22)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°1.3.2: INFORMATION ABOUT TYPES AND NANs\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset.\n",
    "@post: Statistics and/or visualization on the presence of missing data in `df`.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the data types and the count of non-null values\n",
    "print(\"Data Types and Non-Null Counts:\\n\")\n",
    "print(df.info())\n",
    "\n",
    "# Count the number of missing values per column\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "# Create a summary table for missing data\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"Missing Values\": missing_values,\n",
    "    \"Percentage Missing\": missing_percentage\n",
    "}).sort_values(by=\"Missing Values\", ascending=False)\n",
    "\n",
    "# Bar plot of missing percentages\n",
    "plt.figure(figsize=(12, 6))\n",
    "missing_summary[missing_summary[\"Missing Values\"] > 0][\"Percentage Missing\"].plot(\n",
    "    kind=\"bar\", color=\"violet\", edgecolor=\"black\"\n",
    ")\n",
    "plt.title(\"Percentage of Missing Data by Column\")\n",
    "plt.ylabel(\"Percentage Missing\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>[Remark 1.2] Each problem has its own solution</b> <br>\n",
    "There exist numerous ways to deal with missing information and we will discuss the two main approaches:\n",
    "<ol>\n",
    "   <li> you remove rows or columns that contain missing data;\n",
    "   <li> or you replace NaNs with another value. The latter can be a fixed value or computed to be, e.g., the mean of all non-NaNs values. The topic of replacing missing data, also called imputation of missing values, is very broad and complex, and there is no global solution that applies everywhere. Maybe you can find one that works well here?\n",
    "</ol>\n",
    "    \n",
    "You **should** read more about how to imput missing value [here](https://scikit-learn.org/stable/modules/impute.html). However, you will not be evaluated on how sophisticated your handling of NaNs is so, for this hackathon, do not spend an unreasonable amount of time on the next cell.\n",
    "</div> \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 1.2] Handling missing data </b>  <br>\n",
    "Given the dataset and the amount / type of missing information, what strategy do you propose to follow regarding missing data (NaNs)? <br> You can choose one or many of the following:\n",
    "<ol>\n",
    "   <li> drop features (column) with missing information; \n",
    "   <li> drop samples (row) with missing information;\n",
    "   <li> replace missing information with interpolation / extrapolation / simple substitution / ...\n",
    "</ol>\n",
    "Justify briefly your choice.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6172 entries, 0 to 7213\n",
      "Data columns (total 26 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   sex                      6172 non-null   object \n",
      " 1   race                     6172 non-null   object \n",
      " 2   c_jail_in                6172 non-null   object \n",
      " 3   c_jail_out               6172 non-null   object \n",
      " 4   in_custody               6172 non-null   object \n",
      " 5   out_custody              6172 non-null   object \n",
      " 6   two_year_recid           6172 non-null   int64  \n",
      " 7   juv_fel_count            6172 non-null   int64  \n",
      " 8   decile_score             6172 non-null   int64  \n",
      " 9   juv_misd_count           6172 non-null   int64  \n",
      " 10  juv_other_count          6172 non-null   int64  \n",
      " 11  priors_count             6172 non-null   int64  \n",
      " 12  c_offense_date           6172 non-null   object \n",
      " 13  c_charge_degree          6172 non-null   object \n",
      " 14  is_recid                 6172 non-null   int64  \n",
      " 15  is_violent_recid         6172 non-null   int64  \n",
      " 16  type_of_assessment       6172 non-null   object \n",
      " 17  decile_score.1           6172 non-null   int64  \n",
      " 18  score_text               6172 non-null   object \n",
      " 19  screening_date           6172 non-null   object \n",
      " 20  v_type_of_assessment     6172 non-null   object \n",
      " 21  decile_score             6172 non-null   int64  \n",
      " 22  v_score_text             6172 non-null   object \n",
      " 23  v_screening_date         6172 non-null   object \n",
      " 24  priors_count.1           6172 non-null   int64  \n",
      " 25  days_b_screening_arrest  6172 non-null   float64\n",
      "dtypes: float64(1), int64(11), object(14)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°1.3.3: Handling missing values\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset.\n",
    "@post: A pandas.DataFrame `df` containing the dataset with no missing values.\n",
    "\"\"\"\n",
    "from pandas.api.types import is_numeric_dtype, is_object_dtype\n",
    "\n",
    "#Quand une feature a un haut pourcentage de valeurs manquantes >50% il vaut mieux le laisser tomber afin d'éviter d'avoi des biais a cause de cette feauture\n",
    "#Quand la feature est essentielle pour la prédiciton il vaut mieux representer cette valeur manquante par la meadiane/moyenne/mode\n",
    "#Quand la data manquante n'est pas random c'est a dire par exemple pour uen fetaure en particulier il en manque bcp comme chez nous chez violent_recid il faut faire attention avant de retirer cette info pour ne pas créer des biais \n",
    "# vr_offense_date sera drope car il manque plus de 50% des data\n",
    "# two_year_recid, priors_count, is_recid seront drop aussi car il manque trop d'infos et donc tirer des conclusions sur ces secteurs importatnts avec pas assez d'infos va nous faire créer des biais non fondés\n",
    "#Use mean or median for continuous numerical data like priors_count or r_days_from_arrest.\n",
    "#Replace missing values with the mode (most frequent value) or a placeholder such as \"unknown\" for categorical features like c_charge_degree or r_charge_desc.\n",
    "\n",
    "# Drop features with more than 50% missing values\n",
    "threshold = 0.5 * len(df)\n",
    "df = df.dropna(axis=1, thresh=threshold)\n",
    "\n",
    "# Drop rows with missing critical features\n",
    "critical_features = [\"two_year_recid\", \"priors_count\", \"is_recid\"]\n",
    "df = df.dropna(subset=critical_features)\n",
    "\n",
    "for col in df.columns:\n",
    "    if is_numeric_dtype(df[col]):  # Check if the column is numerical\n",
    "        df[col].fillna(df[col].median(), inplace=True)  # Median imputation\n",
    "    elif is_object_dtype(df[col]):  # Check if the column is categorical\n",
    "        df[col].fillna(\"unknown\", inplace=True)  # Placeholder for missing categories\n",
    "\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>1.4 - Feature engineering</b> <br>\n",
    "</font>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>[Remark 1.3] New features extraction</b> <br>\n",
    "In the present case, some features in the dataset still need to be reworked in order to provide meaningful information. For example, working with datetimes might not be easy.\n",
    "</div>\n",
    "\n",
    "You may want to somehow incorporate the information about date and time into the dataset in a more **intelligent** manner than it was before. Again, there can be multiple solutions, and we will propose you a very simple one.\n",
    "\n",
    "For example, what is most important to predict the likelihood of recidivism: the exact dates at which each defendant entered and left jail/custody or the time spent in jail/custody?\n",
    "\n",
    "Note: 1) you should apply your solution to all the \"date/time\" features you kept. There should at least be the one hinted above. 2) Pandas has a to_datetime function that should prove useful !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6172 entries, 0 to 7213\n",
      "Data columns (total 43 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   sex                             6172 non-null   object        \n",
      " 1   race                            6172 non-null   object        \n",
      " 2   c_jail_in                       6172 non-null   datetime64[ns]\n",
      " 3   c_jail_out                      6172 non-null   datetime64[ns]\n",
      " 4   in_custody                      6172 non-null   object        \n",
      " 5   out_custody                     6172 non-null   object        \n",
      " 6   two_year_recid                  6172 non-null   int64         \n",
      " 7   juv_fel_count                   6172 non-null   int64         \n",
      " 8   decile_score                    6172 non-null   int64         \n",
      " 9   juv_misd_count                  6172 non-null   int64         \n",
      " 10  juv_other_count                 6172 non-null   int64         \n",
      " 11  priors_count                    6172 non-null   int64         \n",
      " 12  c_offense_date                  5388 non-null   datetime64[ns]\n",
      " 13  c_charge_degree                 6172 non-null   object        \n",
      " 14  is_recid                        6172 non-null   int64         \n",
      " 15  is_violent_recid                6172 non-null   int64         \n",
      " 16  type_of_assessment              6172 non-null   object        \n",
      " 17  decile_score.1                  6172 non-null   int64         \n",
      " 18  score_text                      6172 non-null   object        \n",
      " 19  screening_date                  6172 non-null   datetime64[ns]\n",
      " 20  v_type_of_assessment            6172 non-null   object        \n",
      " 21  decile_score                    6172 non-null   int64         \n",
      " 22  v_score_text                    6172 non-null   object        \n",
      " 23  v_screening_date                6172 non-null   datetime64[ns]\n",
      " 24  priors_count.1                  6172 non-null   int64         \n",
      " 25  days_b_screening_arrest         6172 non-null   float64       \n",
      " 26  time_in_jail                    6172 non-null   int64         \n",
      " 27  days_between_screening_offense  5388 non-null   float64       \n",
      " 28  c_jail_in_weekday               6172 non-null   int32         \n",
      " 29  c_jail_in_month                 6172 non-null   int32         \n",
      " 30  c_jail_in_year                  6172 non-null   int32         \n",
      " 31  c_jail_out_weekday              6172 non-null   int32         \n",
      " 32  c_jail_out_month                6172 non-null   int32         \n",
      " 33  c_jail_out_year                 6172 non-null   int32         \n",
      " 34  c_offense_date_weekday          5388 non-null   float64       \n",
      " 35  c_offense_date_month            5388 non-null   float64       \n",
      " 36  c_offense_date_year             5388 non-null   float64       \n",
      " 37  screening_date_weekday          6172 non-null   int32         \n",
      " 38  screening_date_month            6172 non-null   int32         \n",
      " 39  screening_date_year             6172 non-null   int32         \n",
      " 40  v_screening_date_weekday        6172 non-null   int32         \n",
      " 41  v_screening_date_month          6172 non-null   int32         \n",
      " 42  v_screening_date_year           6172 non-null   int32         \n",
      "dtypes: datetime64[ns](5), float64(5), int32(12), int64(12), object(9)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°1.4 : FEATURE ENGINEERING\n",
    "\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset\n",
    "@post: A pandas.DataFrame `df` containing the previous dataset with the new features you created.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "date_columns = [\n",
    "    \"c_jail_in\", \"c_jail_out\", \"c_offense_date\", \"c_arrest_date\",\n",
    "    \"r_offense_date\", \"r_jail_in\", \"r_jail_out\", \"screening_date\", \"vr_offense_date\", \"v_screening_date\"\n",
    "]\n",
    "\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")  \n",
    "\n",
    "# 1. Time spent in custody (in days)\n",
    "if \"c_jail_in\" in df.columns and \"c_jail_out\" in df.columns:\n",
    "    df[\"time_in_jail\"] = (df[\"c_jail_out\"] - df[\"c_jail_in\"]).dt.days\n",
    "\n",
    "# 2. Days between arrest and offense\n",
    "if \"c_offense_date\" in df.columns and \"c_arrest_date\" in df.columns:\n",
    "    df[\"days_between_arrest_offense\"] = (df[\"c_offense_date\"] - df[\"c_arrest_date\"]).dt.days\n",
    "\n",
    "# 3. Days between screening and offense (useful for timing of assessments)\n",
    "if \"screening_date\" in df.columns and \"c_offense_date\" in df.columns:\n",
    "    df[\"days_between_screening_offense\"] = (df[\"screening_date\"] - df[\"c_offense_date\"]).dt.days\n",
    "\n",
    "# Optional: Extract day of the week, month, and year\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[f\"{col}_weekday\"] = df[col].dt.weekday  # Day of the week (0=Monday, 6=Sunday)\n",
    "        df[f\"{col}_month\"] = df[col].dt.month  # Month (1-12)\n",
    "        df[f\"{col}_year\"] = df[col].dt.year  # Year\n",
    "\n",
    "df.info() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 1.3] New features </b>  <br>\n",
    "What features have you added? If a particular manipulation has been applied, please explain.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>1.5 - Sensitive features</b> <br>\n",
    "</font>\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>[Remark 1.4] Sensitive features</b> <br>\n",
    "At this stage of the Hackathon, you still have two sensitive features, the sex attribute and the race attribute. As the end goal is to build a fair learning algorithm, you should not reasonably use these two features to determine if there is a risk of recidivism of the defendant.\n",
    "</div>\n",
    "\n",
    "To check if your learning techniques are unfair to particular subgroups of these features, you should **remove both features from the dataset while keeping them aside** to analyze the fairness of our learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6172 entries, 0 to 7213\n",
      "Data columns (total 42 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   sex                             6172 non-null   int64         \n",
      " 1   race                            6172 non-null   int64         \n",
      " 2   c_jail_in                       6172 non-null   datetime64[ns]\n",
      " 3   c_jail_out                      6172 non-null   datetime64[ns]\n",
      " 4   in_custody                      6172 non-null   object        \n",
      " 5   out_custody                     6172 non-null   object        \n",
      " 6   juv_fel_count                   6172 non-null   int64         \n",
      " 7   decile_score                    6172 non-null   int64         \n",
      " 8   juv_misd_count                  6172 non-null   int64         \n",
      " 9   juv_other_count                 6172 non-null   int64         \n",
      " 10  priors_count                    6172 non-null   int64         \n",
      " 11  c_offense_date                  5388 non-null   datetime64[ns]\n",
      " 12  c_charge_degree                 6172 non-null   object        \n",
      " 13  is_recid                        6172 non-null   int64         \n",
      " 14  is_violent_recid                6172 non-null   int64         \n",
      " 15  type_of_assessment              6172 non-null   object        \n",
      " 16  decile_score.1                  6172 non-null   int64         \n",
      " 17  score_text                      6172 non-null   object        \n",
      " 18  screening_date                  6172 non-null   datetime64[ns]\n",
      " 19  v_type_of_assessment            6172 non-null   object        \n",
      " 20  decile_score                    6172 non-null   int64         \n",
      " 21  v_score_text                    6172 non-null   object        \n",
      " 22  v_screening_date                6172 non-null   datetime64[ns]\n",
      " 23  priors_count.1                  6172 non-null   int64         \n",
      " 24  days_b_screening_arrest         6172 non-null   float64       \n",
      " 25  time_in_jail                    6172 non-null   int64         \n",
      " 26  days_between_screening_offense  5388 non-null   float64       \n",
      " 27  c_jail_in_weekday               6172 non-null   int32         \n",
      " 28  c_jail_in_month                 6172 non-null   int32         \n",
      " 29  c_jail_in_year                  6172 non-null   int32         \n",
      " 30  c_jail_out_weekday              6172 non-null   int32         \n",
      " 31  c_jail_out_month                6172 non-null   int32         \n",
      " 32  c_jail_out_year                 6172 non-null   int32         \n",
      " 33  c_offense_date_weekday          5388 non-null   float64       \n",
      " 34  c_offense_date_month            5388 non-null   float64       \n",
      " 35  c_offense_date_year             5388 non-null   float64       \n",
      " 36  screening_date_weekday          6172 non-null   int32         \n",
      " 37  screening_date_month            6172 non-null   int32         \n",
      " 38  screening_date_year             6172 non-null   int32         \n",
      " 39  v_screening_date_weekday        6172 non-null   int32         \n",
      " 40  v_screening_date_month          6172 non-null   int32         \n",
      " 41  v_screening_date_year           6172 non-null   int32         \n",
      "dtypes: datetime64[ns](5), float64(5), int32(12), int64(13), object(7)\n",
      "memory usage: 1.7+ MB\n",
      "First few entries of the sensitive features:\n",
      "Race: [3 0 0 3 1]\n",
      "Sex: [0 0 0 0 0]\n",
      "Target variable (y): [0. 1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping dictionaries for encoding the sensitive features\n",
    "race_map = {\n",
    "    \"African-American\": 0,\n",
    "    \"Caucasian\": 1,\n",
    "    \"Asian\": 2,\n",
    "    \"Other\": 3,\n",
    "    \"Hispanic\": 4,\n",
    "    \"Native American\": 5,\n",
    "}\n",
    "\n",
    "sex_map = {\"Male\": 0, \"Female\": 1}\n",
    "\n",
    "# Encode the 'race' and 'sex' columns using the provided maps\n",
    "df['race'] = df['race'].map(race_map)\n",
    "df['sex'] = df['sex'].map(sex_map)\n",
    "\n",
    "# Separate the sensitive features into numpy arrays\n",
    "race = df['race'].values\n",
    "sex = df['sex'].values\n",
    "\n",
    "# Check if 'two_year_recid' exists before attempting to extract it\n",
    "if 'two_year_recid' in df.columns:\n",
    "    # Extract the target variable 'two_year_recid' and store it in y\n",
    "    y = df[\"two_year_recid\"].astype(float).values\n",
    "    # Remove the target column from the dataframe\n",
    "    df.drop(columns=[\"two_year_recid\"], inplace=True)\n",
    "else:\n",
    "    print(\"Warning: 'two_year_recid' column is not found in the DataFrame.\")\n",
    "\n",
    "# Check the final dataset information (now without sensitive features and target column)\n",
    "df.info()\n",
    "\n",
    "# Optionally, display the first few entries of the sensitive features and the target variable\n",
    "print(\"First few entries of the sensitive features:\")\n",
    "print(f\"Race: {race[:5]}\")\n",
    "print(f\"Sex: {sex[:5]}\")\n",
    "if 'y' in locals():\n",
    "    print(f\"Target variable (y): {y[:5]}\")\n",
    "else:\n",
    "    print(\"Target variable 'y' is not available.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>1.6 - Scaling the dataset</b> <br>\n",
    "</font>\n",
    "\n",
    "***Standardizing*** is important when you work with data because it allows data to be compared with one another.\n",
    "\n",
    "$z$ is the standard score of a population $x$. It can be computed as follows:\n",
    "$$z = \\frac{x-\\mu}{\\sigma}$$\n",
    "with $\\mu$ the mean of the population and $\\sigma$ the standard deviation of the population.\n",
    "\n",
    "Please consult [Wikipedia](https://en.wikipedia.org/wiki/Standard_score) for further information about the standardization.\\\n",
    "Be careful to use the same formula as us, check in `scikit-learn` and check the already existing imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting column decile_score: arg must be a list, tuple, 1-d array, or Series\n",
      "Error converting column decile_score: arg must be a list, tuple, 1-d array, or Series\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6172 entries, 0 to 7213\n",
      "Data columns (total 42 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   sex                             6172 non-null   int64         \n",
      " 1   race                            6172 non-null   int64         \n",
      " 2   c_jail_in                       6172 non-null   datetime64[ns]\n",
      " 3   c_jail_out                      6172 non-null   datetime64[ns]\n",
      " 4   in_custody                      0 non-null      float64       \n",
      " 5   out_custody                     0 non-null      float64       \n",
      " 6   juv_fel_count                   6172 non-null   float64       \n",
      " 7   decile_score                    6172 non-null   int64         \n",
      " 8   juv_misd_count                  6172 non-null   float64       \n",
      " 9   juv_other_count                 6172 non-null   float64       \n",
      " 10  priors_count                    6172 non-null   float64       \n",
      " 11  c_offense_date                  5388 non-null   datetime64[ns]\n",
      " 12  c_charge_degree                 0 non-null      float64       \n",
      " 13  is_recid                        6172 non-null   float64       \n",
      " 14  is_violent_recid                6172 non-null   float64       \n",
      " 15  type_of_assessment              0 non-null      float64       \n",
      " 16  decile_score.1                  6172 non-null   float64       \n",
      " 17  score_text                      0 non-null      float64       \n",
      " 18  screening_date                  6172 non-null   datetime64[ns]\n",
      " 19  v_type_of_assessment            0 non-null      float64       \n",
      " 20  decile_score                    6172 non-null   int64         \n",
      " 21  v_score_text                    0 non-null      float64       \n",
      " 22  v_screening_date                6172 non-null   datetime64[ns]\n",
      " 23  priors_count.1                  6172 non-null   float64       \n",
      " 24  days_b_screening_arrest         6172 non-null   float64       \n",
      " 25  time_in_jail                    6172 non-null   int64         \n",
      " 26  days_between_screening_offense  5388 non-null   float64       \n",
      " 27  c_jail_in_weekday               6172 non-null   int32         \n",
      " 28  c_jail_in_month                 6172 non-null   int32         \n",
      " 29  c_jail_in_year                  6172 non-null   int32         \n",
      " 30  c_jail_out_weekday              6172 non-null   int32         \n",
      " 31  c_jail_out_month                6172 non-null   int32         \n",
      " 32  c_jail_out_year                 6172 non-null   int32         \n",
      " 33  c_offense_date_weekday          5388 non-null   float64       \n",
      " 34  c_offense_date_month            5388 non-null   float64       \n",
      " 35  c_offense_date_year             5388 non-null   float64       \n",
      " 36  screening_date_weekday          6172 non-null   int32         \n",
      " 37  screening_date_month            6172 non-null   int32         \n",
      " 38  screening_date_year             6172 non-null   int32         \n",
      " 39  v_screening_date_weekday        6172 non-null   int32         \n",
      " 40  v_screening_date_month          6172 non-null   int32         \n",
      " 41  v_screening_date_year           6172 non-null   int32         \n",
      "dtypes: datetime64[ns](5), float64(20), int32(12), int64(5)\n",
      "memory usage: 1.7 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>...</th>\n",
       "      <th>c_jail_out_year</th>\n",
       "      <th>c_offense_date_weekday</th>\n",
       "      <th>c_offense_date_month</th>\n",
       "      <th>c_offense_date_year</th>\n",
       "      <th>screening_date_weekday</th>\n",
       "      <th>screening_date_month</th>\n",
       "      <th>screening_date_year</th>\n",
       "      <th>v_screening_date_weekday</th>\n",
       "      <th>v_screening_date_month</th>\n",
       "      <th>v_screening_date_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.172000e+03</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6.172000e+03</td>\n",
       "      <td>6.172000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>5388.000000</td>\n",
       "      <td>5388.000000</td>\n",
       "      <td>5388.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.190376</td>\n",
       "      <td>0.856286</td>\n",
       "      <td>2013-09-19 16:29:56.500324096</td>\n",
       "      <td>2013-10-04 19:12:47.595592960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.151236e-18</td>\n",
       "      <td>4.418503</td>\n",
       "      <td>-5.756179e-18</td>\n",
       "      <td>2.216129e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>2013.325664</td>\n",
       "      <td>3.004269</td>\n",
       "      <td>5.679473</td>\n",
       "      <td>2013.252970</td>\n",
       "      <td>2.790668</td>\n",
       "      <td>5.655055</td>\n",
       "      <td>2013.296014</td>\n",
       "      <td>2.790668</td>\n",
       "      <td>5.655055</td>\n",
       "      <td>2013.296014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>2013-01-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.279228e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.832315e-01</td>\n",
       "      <td>-2.351024e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2013-04-02 00:00:00</td>\n",
       "      <td>2013-04-17 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.279228e-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.832315e-01</td>\n",
       "      <td>-2.351024e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2013-09-11 00:00:00</td>\n",
       "      <td>2013-09-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.279228e-01</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.832315e-01</td>\n",
       "      <td>-2.351024e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2014-01-24 00:00:00</td>\n",
       "      <td>2014-02-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.279228e-01</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-1.832315e-01</td>\n",
       "      <td>-2.351024e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2015-01-10 00:00:00</td>\n",
       "      <td>2015-10-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.301630e+01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.593003e+01</td>\n",
       "      <td>1.888564e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.392629</td>\n",
       "      <td>1.221501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000081e+00</td>\n",
       "      <td>2.839463</td>\n",
       "      <td>1.000081e+00</td>\n",
       "      <td>1.000081e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488967</td>\n",
       "      <td>1.996047</td>\n",
       "      <td>3.728822</td>\n",
       "      <td>0.790256</td>\n",
       "      <td>1.973473</td>\n",
       "      <td>3.714591</td>\n",
       "      <td>0.456534</td>\n",
       "      <td>1.973473</td>\n",
       "      <td>3.714591</td>\n",
       "      <td>0.456534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sex         race                      c_jail_in  \\\n",
       "count  6172.000000  6172.000000                           6172   \n",
       "mean      0.190376     0.856286  2013-09-19 16:29:56.500324096   \n",
       "min       0.000000     0.000000            2013-01-01 00:00:00   \n",
       "25%       0.000000     0.000000            2013-04-02 00:00:00   \n",
       "50%       0.000000     0.000000            2013-09-11 00:00:00   \n",
       "75%       0.000000     1.000000            2014-01-24 00:00:00   \n",
       "max       1.000000     5.000000            2015-01-10 00:00:00   \n",
       "std       0.392629     1.221501                            NaN   \n",
       "\n",
       "                          c_jail_out  in_custody  out_custody  juv_fel_count  \\\n",
       "count                           6172         0.0          0.0   6.172000e+03   \n",
       "mean   2013-10-04 19:12:47.595592960         NaN          NaN   1.151236e-18   \n",
       "min              2013-01-02 00:00:00         NaN          NaN  -1.279228e-01   \n",
       "25%              2013-04-17 00:00:00         NaN          NaN  -1.279228e-01   \n",
       "50%              2013-09-26 00:00:00         NaN          NaN  -1.279228e-01   \n",
       "75%              2014-02-04 00:00:00         NaN          NaN  -1.279228e-01   \n",
       "max              2015-10-13 00:00:00         NaN          NaN   4.301630e+01   \n",
       "std                              NaN         NaN          NaN   1.000081e+00   \n",
       "\n",
       "       decile_score  juv_misd_count  juv_other_count  ...  c_jail_out_year  \\\n",
       "count   6172.000000    6.172000e+03     6.172000e+03  ...      6172.000000   \n",
       "mean       4.418503   -5.756179e-18     2.216129e-17  ...      2013.325664   \n",
       "min        1.000000   -1.832315e-01    -2.351024e-01  ...      2013.000000   \n",
       "25%        2.000000   -1.832315e-01    -2.351024e-01  ...      2013.000000   \n",
       "50%        4.000000   -1.832315e-01    -2.351024e-01  ...      2013.000000   \n",
       "75%        7.000000   -1.832315e-01    -2.351024e-01  ...      2014.000000   \n",
       "max       10.000000    2.593003e+01     1.888564e+01  ...      2015.000000   \n",
       "std        2.839463    1.000081e+00     1.000081e+00  ...         0.488967   \n",
       "\n",
       "      c_offense_date_weekday  c_offense_date_month  c_offense_date_year  \\\n",
       "count            5388.000000           5388.000000          5388.000000   \n",
       "mean                3.004269              5.679473          2013.252970   \n",
       "min                 0.000000              1.000000          1987.000000   \n",
       "25%                 1.000000              2.000000          2013.000000   \n",
       "50%                 3.000000              5.000000          2013.000000   \n",
       "75%                 5.000000              9.000000          2014.000000   \n",
       "max                 6.000000             12.000000          2014.000000   \n",
       "std                 1.996047              3.728822             0.790256   \n",
       "\n",
       "       screening_date_weekday  screening_date_month  screening_date_year  \\\n",
       "count             6172.000000           6172.000000          6172.000000   \n",
       "mean                 2.790668              5.655055          2013.296014   \n",
       "min                  0.000000              1.000000          2013.000000   \n",
       "25%                  1.000000              2.000000          2013.000000   \n",
       "50%                  3.000000              5.000000          2013.000000   \n",
       "75%                  4.000000              9.000000          2014.000000   \n",
       "max                  6.000000             12.000000          2014.000000   \n",
       "std                  1.973473              3.714591             0.456534   \n",
       "\n",
       "       v_screening_date_weekday v_screening_date_month  v_screening_date_year  \n",
       "count               6172.000000            6172.000000            6172.000000  \n",
       "mean                   2.790668               5.655055            2013.296014  \n",
       "min                    0.000000               1.000000            2013.000000  \n",
       "25%                    1.000000               2.000000            2013.000000  \n",
       "50%                    3.000000               5.000000            2013.000000  \n",
       "75%                    4.000000               9.000000            2014.000000  \n",
       "max                    6.000000              12.000000            2014.000000  \n",
       "std                    1.973473               3.714591               0.456534  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "def scale_dataset(df):\n",
    "    columns_to_scale = [\n",
    "        \"in_custody\",\n",
    "        \"out_custody\",\n",
    "        \"juv_fel_count\",\n",
    "        \"decile_score\",\n",
    "        \"juv_misd_count\", \n",
    "        \"juv_other_count\", \n",
    "        \"priors_count\", \n",
    "        \"c_charge_degree\", \n",
    "        \"is_recid\", \n",
    "        \"is_violent_recid\", \n",
    "        \"type_of_assessment\", \n",
    "        \"decile_score.1\",\n",
    "        \"score_text\", \n",
    "        \"v_type_of_assessment\", \n",
    "        \"decile_score\", \n",
    "        \"v_score_text\", \n",
    "        \"priors_count.1\", \n",
    "        \"days_b_screening_arrest\"\n",
    "    ]\n",
    "    \n",
    "    # Check for missing columns\n",
    "    missing_columns = [col for col in columns_to_scale if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(\"Missing columns: \", missing_columns)\n",
    "        # Remove missing columns from the list\n",
    "        columns_to_scale = [col for col in columns_to_scale if col in df.columns]\n",
    "        print(\"Columns to scale after adjustment:\", columns_to_scale)\n",
    "    \n",
    "    numeric_columns_to_scale = []\n",
    "    for col in columns_to_scale:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                # Try converting each column to numeric\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')  # Converts non-numeric to NaN\n",
    "                numeric_columns_to_scale.append(col)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting column {col}: {e}\")\n",
    "    \n",
    "    # Handle missing values by filling with the mean of the numeric columns\n",
    "    df[numeric_columns_to_scale] = df[numeric_columns_to_scale].fillna(df[numeric_columns_to_scale].mean())\n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_columns_to_scale] = scaler.fit_transform(df[numeric_columns_to_scale])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "X = scale_dataset(df)\n",
    "X.info()\n",
    "X.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting column decile_score: arg must be a list, tuple, 1-d array, or Series\n",
      "Error converting column decile_score: arg must be a list, tuple, 1-d array, or Series\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6172 entries, 0 to 7213\n",
      "Data columns (total 42 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   sex                             6172 non-null   int64         \n",
      " 1   race                            6172 non-null   int64         \n",
      " 2   c_jail_in                       6172 non-null   datetime64[ns]\n",
      " 3   c_jail_out                      6172 non-null   datetime64[ns]\n",
      " 4   in_custody                      0 non-null      float64       \n",
      " 5   out_custody                     0 non-null      float64       \n",
      " 6   juv_fel_count                   6172 non-null   float64       \n",
      " 7   decile_score                    6172 non-null   int64         \n",
      " 8   juv_misd_count                  6172 non-null   float64       \n",
      " 9   juv_other_count                 6172 non-null   float64       \n",
      " 10  priors_count                    6172 non-null   float64       \n",
      " 11  c_offense_date                  5388 non-null   datetime64[ns]\n",
      " 12  c_charge_degree                 0 non-null      float64       \n",
      " 13  is_recid                        6172 non-null   float64       \n",
      " 14  is_violent_recid                6172 non-null   float64       \n",
      " 15  type_of_assessment              0 non-null      float64       \n",
      " 16  decile_score.1                  6172 non-null   float64       \n",
      " 17  score_text                      0 non-null      float64       \n",
      " 18  screening_date                  6172 non-null   datetime64[ns]\n",
      " 19  v_type_of_assessment            0 non-null      float64       \n",
      " 20  decile_score                    6172 non-null   int64         \n",
      " 21  v_score_text                    0 non-null      float64       \n",
      " 22  v_screening_date                6172 non-null   datetime64[ns]\n",
      " 23  priors_count.1                  6172 non-null   float64       \n",
      " 24  days_b_screening_arrest         6172 non-null   float64       \n",
      " 25  time_in_jail                    6172 non-null   int64         \n",
      " 26  days_between_screening_offense  5388 non-null   float64       \n",
      " 27  c_jail_in_weekday               6172 non-null   int32         \n",
      " 28  c_jail_in_month                 6172 non-null   int32         \n",
      " 29  c_jail_in_year                  6172 non-null   int32         \n",
      " 30  c_jail_out_weekday              6172 non-null   int32         \n",
      " 31  c_jail_out_month                6172 non-null   int32         \n",
      " 32  c_jail_out_year                 6172 non-null   int32         \n",
      " 33  c_offense_date_weekday          5388 non-null   float64       \n",
      " 34  c_offense_date_month            5388 non-null   float64       \n",
      " 35  c_offense_date_year             5388 non-null   float64       \n",
      " 36  screening_date_weekday          6172 non-null   int32         \n",
      " 37  screening_date_month            6172 non-null   int32         \n",
      " 38  screening_date_year             6172 non-null   int32         \n",
      " 39  v_screening_date_weekday        6172 non-null   int32         \n",
      " 40  v_screening_date_month          6172 non-null   int32         \n",
      " 41  v_screening_date_year           6172 non-null   int32         \n",
      "dtypes: datetime64[ns](5), float64(20), int32(12), int64(5)\n",
      "memory usage: 1.7 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>...</th>\n",
       "      <th>c_jail_out_year</th>\n",
       "      <th>c_offense_date_weekday</th>\n",
       "      <th>c_offense_date_month</th>\n",
       "      <th>c_offense_date_year</th>\n",
       "      <th>screening_date_weekday</th>\n",
       "      <th>screening_date_month</th>\n",
       "      <th>screening_date_year</th>\n",
       "      <th>v_screening_date_weekday</th>\n",
       "      <th>v_screening_date_month</th>\n",
       "      <th>v_screening_date_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172</td>\n",
       "      <td>6172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.172000e+03</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6.172000e+03</td>\n",
       "      <td>6.172000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>5388.000000</td>\n",
       "      <td>5388.000000</td>\n",
       "      <td>5388.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.190376</td>\n",
       "      <td>0.856286</td>\n",
       "      <td>2013-09-19 16:29:56.500324096</td>\n",
       "      <td>2013-10-04 19:12:47.595592960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.295685e-17</td>\n",
       "      <td>4.418503</td>\n",
       "      <td>-5.756179e-18</td>\n",
       "      <td>-3.540050e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>2013.325664</td>\n",
       "      <td>3.004269</td>\n",
       "      <td>5.679473</td>\n",
       "      <td>2013.252970</td>\n",
       "      <td>2.790668</td>\n",
       "      <td>5.655055</td>\n",
       "      <td>2013.296014</td>\n",
       "      <td>2.790668</td>\n",
       "      <td>5.655055</td>\n",
       "      <td>2013.296014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>2013-01-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.279228e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.832315e-01</td>\n",
       "      <td>-2.351024e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2013-04-02 00:00:00</td>\n",
       "      <td>2013-04-17 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.279228e-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.832315e-01</td>\n",
       "      <td>-2.351024e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2013-09-11 00:00:00</td>\n",
       "      <td>2013-09-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.279228e-01</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.832315e-01</td>\n",
       "      <td>-2.351024e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2014-01-24 00:00:00</td>\n",
       "      <td>2014-02-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.279228e-01</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-1.832315e-01</td>\n",
       "      <td>-2.351024e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2015-01-10 00:00:00</td>\n",
       "      <td>2015-10-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.301630e+01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.593003e+01</td>\n",
       "      <td>1.888564e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.392629</td>\n",
       "      <td>1.221501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000081e+00</td>\n",
       "      <td>2.839463</td>\n",
       "      <td>1.000081e+00</td>\n",
       "      <td>1.000081e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488967</td>\n",
       "      <td>1.996047</td>\n",
       "      <td>3.728822</td>\n",
       "      <td>0.790256</td>\n",
       "      <td>1.973473</td>\n",
       "      <td>3.714591</td>\n",
       "      <td>0.456534</td>\n",
       "      <td>1.973473</td>\n",
       "      <td>3.714591</td>\n",
       "      <td>0.456534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sex         race                      c_jail_in  \\\n",
       "count  6172.000000  6172.000000                           6172   \n",
       "mean      0.190376     0.856286  2013-09-19 16:29:56.500324096   \n",
       "min       0.000000     0.000000            2013-01-01 00:00:00   \n",
       "25%       0.000000     0.000000            2013-04-02 00:00:00   \n",
       "50%       0.000000     0.000000            2013-09-11 00:00:00   \n",
       "75%       0.000000     1.000000            2014-01-24 00:00:00   \n",
       "max       1.000000     5.000000            2015-01-10 00:00:00   \n",
       "std       0.392629     1.221501                            NaN   \n",
       "\n",
       "                          c_jail_out  in_custody  out_custody  juv_fel_count  \\\n",
       "count                           6172         0.0          0.0   6.172000e+03   \n",
       "mean   2013-10-04 19:12:47.595592960         NaN          NaN  -5.295685e-17   \n",
       "min              2013-01-02 00:00:00         NaN          NaN  -1.279228e-01   \n",
       "25%              2013-04-17 00:00:00         NaN          NaN  -1.279228e-01   \n",
       "50%              2013-09-26 00:00:00         NaN          NaN  -1.279228e-01   \n",
       "75%              2014-02-04 00:00:00         NaN          NaN  -1.279228e-01   \n",
       "max              2015-10-13 00:00:00         NaN          NaN   4.301630e+01   \n",
       "std                              NaN         NaN          NaN   1.000081e+00   \n",
       "\n",
       "       decile_score  juv_misd_count  juv_other_count  ...  c_jail_out_year  \\\n",
       "count   6172.000000    6.172000e+03     6.172000e+03  ...      6172.000000   \n",
       "mean       4.418503   -5.756179e-18    -3.540050e-17  ...      2013.325664   \n",
       "min        1.000000   -1.832315e-01    -2.351024e-01  ...      2013.000000   \n",
       "25%        2.000000   -1.832315e-01    -2.351024e-01  ...      2013.000000   \n",
       "50%        4.000000   -1.832315e-01    -2.351024e-01  ...      2013.000000   \n",
       "75%        7.000000   -1.832315e-01    -2.351024e-01  ...      2014.000000   \n",
       "max       10.000000    2.593003e+01     1.888564e+01  ...      2015.000000   \n",
       "std        2.839463    1.000081e+00     1.000081e+00  ...         0.488967   \n",
       "\n",
       "      c_offense_date_weekday  c_offense_date_month  c_offense_date_year  \\\n",
       "count            5388.000000           5388.000000          5388.000000   \n",
       "mean                3.004269              5.679473          2013.252970   \n",
       "min                 0.000000              1.000000          1987.000000   \n",
       "25%                 1.000000              2.000000          2013.000000   \n",
       "50%                 3.000000              5.000000          2013.000000   \n",
       "75%                 5.000000              9.000000          2014.000000   \n",
       "max                 6.000000             12.000000          2014.000000   \n",
       "std                 1.996047              3.728822             0.790256   \n",
       "\n",
       "       screening_date_weekday  screening_date_month  screening_date_year  \\\n",
       "count             6172.000000           6172.000000          6172.000000   \n",
       "mean                 2.790668              5.655055          2013.296014   \n",
       "min                  0.000000              1.000000          2013.000000   \n",
       "25%                  1.000000              2.000000          2013.000000   \n",
       "50%                  3.000000              5.000000          2013.000000   \n",
       "75%                  4.000000              9.000000          2014.000000   \n",
       "max                  6.000000             12.000000          2014.000000   \n",
       "std                  1.973473              3.714591             0.456534   \n",
       "\n",
       "       v_screening_date_weekday v_screening_date_month  v_screening_date_year  \n",
       "count               6172.000000            6172.000000            6172.000000  \n",
       "mean                   2.790668               5.655055            2013.296014  \n",
       "min                    0.000000               1.000000            2013.000000  \n",
       "25%                    1.000000               2.000000            2013.000000  \n",
       "50%                    3.000000               5.000000            2013.000000  \n",
       "75%                    4.000000               9.000000            2014.000000  \n",
       "max                    6.000000              12.000000            2014.000000  \n",
       "std                    1.973473               3.714591               0.456534  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "def scale_dataset(df):\n",
    "    columns_to_scale = [\n",
    "        \"in_custody\",\n",
    "        \"out_custody\",\n",
    "        \"juv_fel_count\",\n",
    "        \"decile_score\",\n",
    "        \"juv_misd_count\", \n",
    "        \"juv_other_count\", \n",
    "        \"priors_count\", \n",
    "        \"c_charge_degree\", \n",
    "        \"is_recid\", \n",
    "        \"is_violent_recid\", \n",
    "        \"type_of_assessment\", \n",
    "        \"decile_score.1\",\n",
    "        \"score_text\", \n",
    "        \"v_type_of_assessment\", \n",
    "        \"decile_score\", \n",
    "        \"v_score_text\", \n",
    "        \"priors_count.1\", \n",
    "        \"days_b_screening_arrest\"\n",
    "    ]\n",
    "    \n",
    "    # Check for missing columns\n",
    "    missing_columns = [col for col in columns_to_scale if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(\"Missing columns: \", missing_columns)\n",
    "        # Remove missing columns from the list\n",
    "        columns_to_scale = [col for col in columns_to_scale if col in df.columns]\n",
    "        print(\"Columns to scale after adjustment:\", columns_to_scale)\n",
    "    \n",
    "    numeric_columns_to_scale = []\n",
    "    for col in columns_to_scale:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                # Try converting each column to numeric\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')  # Converts non-numeric to NaN\n",
    "                numeric_columns_to_scale.append(col)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting column {col}: {e}\")\n",
    "    \n",
    "    # Handle missing values by filling with the mean of the numeric columns\n",
    "    df[numeric_columns_to_scale] = df[numeric_columns_to_scale].fillna(df[numeric_columns_to_scale].mean())\n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_columns_to_scale] = scaler.fit_transform(df[numeric_columns_to_scale])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "X = scale_dataset(df)\n",
    "X.info()\n",
    "X.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=7 color=#009999> <b>PART 2 - Data Exploration</b> </font> <br><br>\n",
    "\n",
    "<font size=5 color=#009999> <b>2.1 - Feature visualization</b> <br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the dataset balanced in terms of sensitive groups ?\n",
    "It's good practice to check this to better understand the contents of our dataset.\n",
    "Indeed, if the training dataset is severely imbalanced, our learning algorithm may perform better for over-represented groups than for under-represented groups. Moreover, our goal is for the model to perform equally well across all groups.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 2.1] (Im)Balanced dataset ? </b>  <br>\n",
    "Is the dataset imbalanced ? What could be the consequences in terms of fairness i.e. in terms of the model performing equally well across all groups ?\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL N°2.1.1: (Im)Balanced dataset ?\n",
    "\n",
    "@pre:  A pandas.DataFrame `X` containing the dataset\n",
    "@post: A pie chart plot representing the repartition of race groups in the dataset.\n",
    "\"\"\"\n",
    "\n",
    "# As the race group was previously removed, we can temporarily add it back, using the following map.\n",
    "race_reverse_map = {v: k for k, v in race_map.items()}\n",
    "\n",
    "\n",
    "X = X.drop(columns=[\"race\"])  # Remove the race group again after doing the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "In order to check to the important features in our dataset, we can compute and plot (see e.g. `sns.heatmap`) the correlation matrix, as a tool to visually show all the correlation between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL N°2.1.2 : Correlation matrix\n",
    "\n",
    "@pre:  A pandas.DataFrame `df` containing the dataset\n",
    "@post: A visualization of the correlation matrix between features.\n",
    "\"\"\"\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>2.2 Principal Component Analysis</b> <br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is often considered as the simplest and most fundamental technique used in dimensionality reduction. Remember that PCA is essentially the rotation of coordinate axes, chosen such that each successful axis captures or preserves as much variance as possible. If the algorithm returns a new system coordinates of the same dimension as the input, we can keep only the axis corresponding to the 3 largest singular values and project data on this coordinates system to perform the visualization.\n",
    "\n",
    "To vizualize the importance of features, we can extract the PCA loadings. These are indicators of the correlation between components and original features. The value of loadings is contained between -1 and 1. The more the value goes toward those boundaries, the more the feature influences the choice of component.We propose to perform a 2-dimensional PCA and then to add the loadings in vector form to the figure to obtain what is called a biplot.\n",
    "\n",
    "The biplot visualization function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL N°2.2.1 : Principal Component Analysis (2D)\n",
    "\n",
    "@pre:  A pandas.DataFrame `X` containing the dataset and labels `y`\n",
    "@post: A PCA visualization in 2D where points are colored with respect to true labels `y`\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def biplot_visualization(X, y, columns=None):\n",
    "    \"\"\"\n",
    "    Plot a biplot graph: the scaled data after applying a 2D PCA with loadings in vector forms.\n",
    "\n",
    "    :param pca: PCA object\n",
    "    :param X: a n by m matrix (or DataFrame), containing the input prior to the PCA transformation\n",
    "    :param y: a vector of length n containing the target\n",
    "    :param columns: a list of length m contained the names of the columns\n",
    "        If not given, X.columns will be used\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=2)\n",
    "    X = pca.fit_transform(X)\n",
    "\n",
    "    columns = (\n",
    "        columns\n",
    "        if columns is not None\n",
    "        else X.columns\n",
    "        if isinstance(X, pd.DataFrame)\n",
    "        else [f\"Feature {i+1}\" for i in range(X.shape[1])]\n",
    "    )\n",
    "\n",
    "    # Normalize data for scaling\n",
    "    X_normalized = X / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "    df = pd.DataFrame(data=X_normalized, columns=[\"PC1\", \"PC2\"])\n",
    "\n",
    "    # Prepare loadings (vector components)\n",
    "    loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "    loadings_df = pd.DataFrame(loadings, columns=[\"PC1\", \"PC2\"], index=columns)\n",
    "\n",
    "    # Create scatter plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(x=df[\"PC1\"], y=df[\"PC2\"], hue=y, palette=\"viridis\", s=70, alpha=0.7)\n",
    "\n",
    "    # Add vectors for loadings\n",
    "    for index, row in loadings_df.iterrows():\n",
    "        plt.arrow(\n",
    "            0,\n",
    "            0,\n",
    "            row.PC1,\n",
    "            row.PC2,\n",
    "            color=\"red\",\n",
    "            alpha=0.7,\n",
    "            head_width=0.02,\n",
    "            head_length=0.03,\n",
    "        )\n",
    "        plt.text(\n",
    "            row.PC1 * 1.1,\n",
    "            row.PC2 * 1.1,\n",
    "            index,\n",
    "            color=\"black\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    # Labels and limits\n",
    "    plt.title(\"Biplot Visualization\", fontsize=14)\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.axvline(0, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(title=\"Classes\", loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# biplot_visualization(X, y, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, you are asked to perform a 3 components PCA and plot it using Plotly.\n",
    "<div class=\"alert alert-danger\">\n",
    " Note: On certain versions of Firefox, the 3D scatter function of plotly may have some issues.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCELL N°2.2.2 : Principal Component Analysis (3D)\\n\\n@pre:  A pandas.DataFrame `X` containing the dataset and labels `y`\\n@post: A PCA visualization in 3D where points are colored with respect to true labels `y`\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°2.2.2 : Principal Component Analysis (3D)\n",
    "\n",
    "@pre:  A pandas.DataFrame `X` containing the dataset and labels `y`\n",
    "@post: A PCA visualization in 3D where points are colored with respect to true labels `y`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 2.2] Principal Component Analysis </b>  <br>\n",
    "Do all features have the same importance? If no, which features are less important, and why? You can use all other graphs from the visualization part to justify your answer.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=7 color=#009999> <b>PART 3 - Clustering</b> </font> <br><br>\n",
    "\n",
    "<font size=4 color=#009999> <b>ABCs of Clustering</b> <br>\n",
    "Clustering can be defined as the task of *grouping* objects from a set $S$ (here, each row/observation is an object) in such a way that objects assigned to the same group (called cluster) are more **similar** (or less **distant**) with respect to each other (in some sense) than to those assigned to the other groups. Usually, we would like to divide our objects into $K$ groups.\n",
    "\n",
    "As such, clustering reduces to finding, among all $K$-partitions possible of $S$, the partition $\\mathcal{P}$ that minimizes some error criterion $f(\\mathcal{P})$. Each object will be assigned a cluster, $C_i$, and each cluster will have its centroid $c_i$ the distance between **any object** in $C_i$ to centroid $c_i$ is **always smaller** that the distance to any other centroid. In other words, each object is assigned to the cluster whose centroid is the closest.\n",
    "\n",
    "\n",
    "A mathematical formulation of the problem could be the following, $$ \\boxed{\\min_{(C_1,\\dots,C_K) \\,\\in\\, \\mathcal{P}}\\,f(C_1,\\dots,C_K) = \\sum_{i = 1}^{K}\\,\\sum_{x \\in C_i}\\,\\Delta(x,c_i)}$$\n",
    "\n",
    "where $\\Delta(x,c_i)$ denotes the distance between object $x$ and centroid $c_i$.\n",
    "\n",
    "<br>\n",
    "<font size=5 color=#009999>\n",
    "EXAMPLE OF SEPARATING OBJECTS INTO 10 CLUSTERS\n",
    "</font> <br> <br>\n",
    "\n",
    "**First**, let us imagine the following 2D dataset.\n",
    "\n",
    "<img src=\"Imgs/10-partitions-data.svg\" width = \"250\">\n",
    "\n",
    "**Then**, a 10-partition is defined by the position of the centroids, one for each cluster. Below, you can observe four examples of (random) centroids localizations (stars).\n",
    "\n",
    "<img src=\"Imgs/10-partitions-chose-centroids.svg\" width = \"1000\">\n",
    "\n",
    "**Next**, the regions are colored based on their closest centroid. Here, we take the distance to be the Euclidean distance.\n",
    "\n",
    "<img src=\"Imgs/10-partitions-centroids.svg\" width = \"1000\">\n",
    "\n",
    "**Finally**, data points (objects) are colored based in the region they are in.\n",
    "\n",
    "<img src=\"Imgs/10-partitions-clusters.svg\" width = \"1000\">\n",
    "\n",
    "<font size=5 color=#009999> <b>3.1 - K-Means</b> <br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCELL N°3.1.1 : GROUND TRUTH\\n\\n@pre:  A pandas.DataFrame `X` containing the dataset and labels `y`\\n@post: A 80/20 split of your dataset in train and test sets.\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°3.1.1 : GROUND TRUTH\n",
    "\n",
    "@pre:  A pandas.DataFrame `X` containing the dataset and labels `y`\n",
    "@post: A 80/20 split of your dataset in train and test sets.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 3.1] Number of clusters </b>  <br>\n",
    "    Accounting for all features, what do you think is the ideal number of clusters? What will happen if too many or even too few clusters are chosen?\n",
    "</div>\n",
    "\n",
    "Now that your dataset is divided into a train and a test set, use the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\">KMeans</a> algorithm from `scikit-learn` to apply the clustering on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CELL N°3.1.2 : K-Means\n",
    "\n",
    "@pre:  A split of your dataset: X_train, X_test, y_train, y_test\n",
    "@post: A split of your dataset in train and test sets.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_and_predict(model, X_train, X_test):\n",
    "    \"\"\"Trains the clustering model on the training data and predict the clusters for both training and test data.\n",
    "\n",
    "    Parameters:\n",
    "    model (sklearn or similar clustering model): The clustering algorithm that has a fit_predict method and a predict method.\n",
    "    X_train (array-like, shape (n_samples, n_features)): The training data to fit the model on.\n",
    "    X_test (array-like, shape (n_samples, n_features)): The test data to predict the clusters for.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two arrays:\n",
    "        - train_clusters (array): Cluster labels for the training data.\n",
    "        - test_clusters (array): Cluster labels for the test data.\n",
    "    \"\"\"\n",
    "    train_clusters = ...  # TODO\n",
    "    test_clusters = ...  # TODO\n",
    "    return train_clusters, test_clusters\n",
    "\n",
    "\n",
    "def compute_y_pred(model, X_train, X_test, y_train):\n",
    "    \"\"\"Compute the predicted labels for the test data based on the clustering model.\n",
    "\n",
    "    This function assigns a predicted label to each sample in the test set by:\n",
    "    1. Training the model on the training data using the previous function.\n",
    "    2. Assigning the majority class from the training labels to each cluster.\n",
    "    3. Using the cluster assignments from the test data to assign predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    model (sklearn or similar clustering model): The trained clustering model with an `n_clusters` attribute.\n",
    "    X_train (array-like, shape (n_samples, n_features)): The training data used to fit the model.\n",
    "    X_test (array-like, shape (n_samples, n_features)): The test data to predict labels for.\n",
    "    y_train (array-like, shape (n_samples,)): The true labels of the training data.\n",
    "\n",
    "    Returns:\n",
    "    np.array: An array of predicted labels for the test data based on the majority class in each cluster.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    train_clusters, test_clusters = train_and_predict(model, X_train, X_test)\n",
    "    df = pd.DataFrame({\"cluster\": train_clusters, \"target\": y_train})\n",
    "\n",
    "    for cluster in range(model.n_clusters):\n",
    "        majority_class = df[df[\"cluster\"] == cluster][\"target\"].mode()[0]\n",
    "        mapping[cluster] = majority_class\n",
    "\n",
    "    y_pred = ...  # TODO\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def compute_metrics(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Computes various evaluation metrics for the clustering model.\n",
    "\n",
    "    Parameters:\n",
    "    model (sklearn or similar clustering model): The trained clustering model with an `n_clusters` attribute.\n",
    "    X_train (array-like, shape (n_samples, n_features)): The training data used to fit the model.\n",
    "    X_test (array-like, shape (n_samples, n_features)): The test data to predict labels for.\n",
    "    y_train (array-like, shape (n_samples,)): The true labels of the training data.\n",
    "    y_test (array-like, shape (n_samples,)): The true labels of the test data.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the computed metrics:\n",
    "        - \"n_clusters\": The number of clusters in the model.\n",
    "        - \"Accuracy\": The accuracy of the model on the test data.\n",
    "        - \"F1-Score\": The F1-score of the model on the test data.\n",
    "        - \"Precision\": The precision of the model on the test data.\n",
    "        - \"Recall\": The recall of the model on the test data.\n",
    "        - \"Silhouette Score\": The silhouette score of the clustering on the test data.\n",
    "    \"\"\"\n",
    "    y_pred = compute_y_pred(model, X_train, X_test, y_train)\n",
    "    accuracy = ...  # TODO\n",
    "    f1 = ...  # TODO\n",
    "    precision, recall, _, _ = ...  # TODO\n",
    "    sil_score = ...  # TODO\n",
    "    return {\n",
    "        \"n_clusters\": ...,  # TODO\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1-Score\": f1,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Silhouette Score\": sil_score,\n",
    "    }\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=random_seed)\n",
    "# results = compute_metrics(kmeans, X_train, y_train, X_test, y_test)\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> <b>3.2 - Results Analysis</b> <br>\n",
    "</font>\n",
    "\n",
    "In this section, we adress the difficult task of evaluating the performance of the clustering algorithm.\n",
    "\n",
    "<font size=3 color=#009999> <b>3.2.1 - Quality of the clustering</b> <br>\n",
    "</font>\n",
    "The silhouette score is a measure of how close each point in one cluster is to points in the neighboring clusters. The [mean silhouette score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) is an average of the silhouette score for each point and provides a way to measure the quality of the clustering.\n",
    "\n",
    "The best value is 1 and the worst value is -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°3.2.1 : Silhouette Score\n",
    "\n",
    "@pre:  A split of your dataset: X_train, X_test, y_train, y_test\n",
    "@post: A \"Mean Silhouette Score versus Number of Clusters\" plot\n",
    "\"\"\"\n",
    "model = KMeans(random_state=42)\n",
    "cluster_range = range(2, 10)\n",
    "\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clusters in cluster_range:\n",
    "    # Set the number of clusters dynamically\n",
    "    model.n_clusters = n_clusters\n",
    "        \n",
    "    # Compute metrics for the current number of clusters\n",
    "    metrics = compute_metrics(model, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "    # Extract the silhouette score\n",
    "    silhouette_scores.append(metrics[\"Silhouette Score\"])\n",
    "    \n",
    "# Plot the silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cluster_range, silhouette_scores, marker='o', linestyle='--', color='teal')\n",
    "plt.title('Mean Silhouette Score versus Number of Clusters', fontsize=16)\n",
    "plt.xlabel('Number of Clusters', fontsize=14)\n",
    "plt.ylabel('Mean Silhouette Score', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>3.2.2 - Purity and entropy of a clustering</b> <br>\n",
    "</font>\n",
    "\n",
    "### Purity\n",
    "\n",
    "Purity measures how well a cluster contains points from a single class. A cluster with high purity mostly contains points from one class.\n",
    "\n",
    "**Example:** Imagine you are grouping fruits based on their shape, but you also have information about their color. If a group contains mostly red apples, that group has high purity. However, if you find a few green apples or pears in the group, the purity decreases. In this case, high purity means the majority of fruits share both shape and color consistency.\n",
    "\n",
    "Formula:\n",
    "$$\n",
    "\\text{Purity } = \\frac{1}{N} \\sum_{i = 1}^k \\max_j n_{i,j}\n",
    "$$\n",
    "where:\n",
    "- $N = $ total number of points,\n",
    "- $k = $ number of clusters,\n",
    "- $n_{i,j} = $​ number of points from class $j$ in cluster $i$,\n",
    "- $\\max_j n_{i,j} = $ number of points from the most common class in cluster $i$.\n",
    "\n",
    "\n",
    "### Entropy\n",
    "\n",
    "Entropy measures how mixed the classes are within a cluster. Low entropy means most points in a cluster belong to the same class. High entropy means points are more evenly distributed across different classes.\n",
    "\n",
    "**Example:** Consider a fruit basket that is mostly filled with red apples, with only a few bananas and oranges. Since the basket is dominated by one type of fruit, it has low entropy. In contrast, if the basket contains an equal mix of apples, bananas, and oranges, the distribution is more random, resulting in high entropy. This even distribution means it is harder to predict the dominant fruit just by looking at the basket.\n",
    "\n",
    "***Formula for a single cluster:***\n",
    "$$\n",
    "E_i = -\\sum_{j=1}^{C} p_{ij} \\log_2(p_{ij})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $C = $ number of classes,\n",
    "- $p_{i,j} = $ proportion of points from class jj in cluster ii.\n",
    "\n",
    "The overall entropy is the weighted average across all clusters:\n",
    "\n",
    "$$\n",
    "\\text{Entropy} = \\frac{1}{N} \\sum_{i=1}^{k} n_i \\cdot E_i\n",
    "$$\n",
    "\n",
    "Where $n_i$​ is the number of points in cluster $i$.\n",
    "\n",
    "A good clustering aims for both high purity (most points in a cluster belong to one class) and low entropy (each cluster contains little class mixing).\n",
    "    \n",
    "<div class=\"alert alert-danger\">\n",
    " If this makes it easier for you to implement purity and entropy, you can modify the previously defined function `compute_metrics` to also return in the results dictionary the purity, the entropy or any other metric that you may want to use later on.\n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    " Compared to the silhouette score which is computed using only the features, purity and entropy are metrics computed using the true label `y`. Do not forget to compute these metrics on a test set.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°3.2.2 : Purity and Entropy\n",
    "\n",
    "@pre:  A split of your dataset: X_train, X_test, y_train, y_test\n",
    "@post: A \"Purity/Entropy versus Number of Clusters\" plot. There should be two curves, one for the purity and one for the entropy.\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 3.2] Quality of the clustering </b>  <br>\n",
    "    You considered three different measures for the quality of the clustering: the first one is the silhouette score and is oblivious to the true labels: it is a truly unsupervised metric. The second and third metric use the true label to assess the quality of the clustering. Based on this observation,\n",
    "    \n",
    "1. Comment on the evolution of each metric according to the number of clusters.\n",
    "2. Comment on what do you now think is the ideal number of clusters ?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=7 color=#009999> <b>PART 4 - Fairness metrics</b> </font> <br><br>\n",
    "\n",
    "Congratulations for reaching this far ! So far, you have thoroughly analyzed a sensitive dataset, you cleaned it and focused on what you believe were useful features for predicting recidivism. You then used the K-Means algorithm to have your own recidivism predictor.\n",
    "\n",
    "Because of the sensitivity of the dataset and its potential negative impact on certain parts of the population, you should now assess its fairness with respect to each gender and race group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>4.1 False Positive Rate</b> <br>\n",
    "</font>\n",
    "\n",
    "The false positive rate (FPR) is a performance metric used to evaluate the accuracy of a machine learning model, particularly in binary classification tasks. It refers to the proportion of actual negative instances (people that did not recidivate) that are incorrectly classified as positive. A lower FPR indicates that the model is better at identifying negative cases.\n",
    "\n",
    "A fair model would have the same FPR across all groups.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    " As for the purity and entropy metrics, the false positive rate metric uses the true labels, you should therefore make a train/test split before hand.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m n_clusters :\n\u001b[1;32m     26\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mj, random_state\u001b[38;5;241m=\u001b[39mrandom_seed)\n\u001b[0;32m---> 27\u001b[0m     cluster \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mfit_predict(X_group)\n\u001b[1;32m     29\u001b[0m     CM \u001b[38;5;241m=\u001b[39m confusion_matrix(y_group,cluster)\n\u001b[1;32m     30\u001b[0m     tp \u001b[38;5;241m=\u001b[39m confusion_matrix[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1071\u001b[0m, in \u001b[0;36m_BaseKMeans.fit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \n\u001b[1;32m   1051\u001b[0m \u001b[38;5;124;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1481\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \n\u001b[1;32m   1457\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1481\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1482\u001b[0m         X,\n\u001b[1;32m   1483\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1484\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32],\n\u001b[1;32m   1485\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1486\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_x,\n\u001b[1;32m   1487\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1488\u001b[0m     )\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m   1492\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    875\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    876\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[1;32m    877\u001b[0m )\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 879\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdtypes_orig)\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[1;32m    882\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "\u001b[0;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°4.1 False Positive Rate\n",
    "\n",
    "@pre:  A split of your dataset: X_train, X_test, y_train, y_test\n",
    "@post: A \"False Positive Rate vs Number of Clusters\" plot for each group\n",
    "\"\"\"\n",
    "\n",
    "# Because the dataset is imbalanced, we will repartition our dataset into three race groups: African-American, Caucasian and Other.\n",
    "group_labels = np.where(race == 0, 0, np.where(race == 1, 1, 2))\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_val = train_test_split(\n",
    "    X, y, group_labels, test_size=0.2, random_state=random_seed\n",
    ")\n",
    "\n",
    "# Doing so, you can now use X_test[group_val == i] to get the test points with race i.\n",
    "\n",
    "n_clusters = range(2,10)\n",
    "FPR_results = {k: [] for k in range(0,2)}\n",
    "\n",
    "for i in range(0,2) : \n",
    "    \n",
    "    X_group = X_test[group_val == i]\n",
    "    y_group = y_test[group_val == i]\n",
    "    \n",
    "    for j in n_clusters :\n",
    "        kmeans = KMeans(n_clusters=j, random_state=random_seed)\n",
    "        cluster = kmeans.fit_predict(X_group)\n",
    "        \n",
    "        CM = confusion_matrix(y_group,cluster)\n",
    "        tp = confusion_matrix[0, 0]\n",
    "        fn = confusion_matrix[0, 1]\n",
    "        fp = confusion_matrix[1, 0]\n",
    "        tn = confusion_matrix[1, 1]\n",
    "        \n",
    "        FPR = fp/(fp+tn)\n",
    "        FPR_results[i].append(FPR)\n",
    "        \n",
    "    plt.plot(n_clusters, FPR_results, label=f\"Groupe {i}\")\n",
    "\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"False Positive Rate\")\n",
    "plt.title(\"False Positive Rate vs. Number of Clusters\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=5 color=#009999> <b>4.2 Demographic Parity</b> <br>\n",
    "</font>\n",
    "Demographic parity is a fairness metric aimed at ensuring that a machine learning model’s predictions do not depend on membership in a sensitive group. Specifically, demographic parity is achieved when the likelihood of a prediction is independent of sensitive group membership. In binary classification, demographic parity requires equal selection rates across groups.\n",
    "\n",
    "In our case, perfect demographic parity means that there is the exact same proportion of “bail denied” in each race group. A fair model would have the same Demographic Parity value across all groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m n_clusters :\n\u001b[1;32m     35\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mj, random_state\u001b[38;5;241m=\u001b[39mrandom_seed)\n\u001b[0;32m---> 36\u001b[0m     cluster \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mfit_predict(X_group)\n\u001b[1;32m     38\u001b[0m     DP \u001b[38;5;241m=\u001b[39m compute_demographic_parity(y_group, i)\n\u001b[1;32m     40\u001b[0m     DP_results[i]\u001b[38;5;241m.\u001b[39mappend(FPR)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1071\u001b[0m, in \u001b[0;36m_BaseKMeans.fit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \n\u001b[1;32m   1051\u001b[0m \u001b[38;5;124;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1481\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \n\u001b[1;32m   1457\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1481\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1482\u001b[0m         X,\n\u001b[1;32m   1483\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1484\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32],\n\u001b[1;32m   1485\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1486\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_x,\n\u001b[1;32m   1487\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1488\u001b[0m     )\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m   1492\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    875\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    876\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[1;32m    877\u001b[0m )\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 879\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdtypes_orig)\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[1;32m    882\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "\u001b[0;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.Int32DType'>)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELL N°4.2 Demographic Parity\n",
    "\n",
    "@pre:  A split of your dataset: X_train, X_test, y_train, y_test\n",
    "@post: A \"Demographic Parity vs Number of Clusters\" plot\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# We provide the function below to compute demographic parity\n",
    "def compute_demographic_parity(y_pred, group_labels):\n",
    "    unique_groups = np.unique(group_labels)\n",
    "    demographic_parity = {}\n",
    "\n",
    "    for group in unique_groups:\n",
    "        # Create a boolean mask for the current group\n",
    "        group_mask = group_labels == group\n",
    "\n",
    "        # Calculate the proportion of positive predictions for the group\n",
    "        group_pred = y_pred[group_mask]\n",
    "        positive_rate = np.mean(group_pred == 1)\n",
    "\n",
    "        demographic_parity[group] = positive_rate\n",
    "\n",
    "    return demographic_parity\n",
    "\n",
    "n_clusters = range(2,10)\n",
    "DP_results = {k: [] for k in range(0,2)}\n",
    "\n",
    "for i in range(0,2) : \n",
    "    \n",
    "    X_group = X_test[group_val == i]\n",
    "    y_group = y_test[group_val == i]\n",
    "    \n",
    "    for j in n_clusters :\n",
    "        kmeans = KMeans(n_clusters=j, random_state=random_seed)\n",
    "        cluster = kmeans.fit_predict(X_group)\n",
    "        \n",
    "        DP = compute_demographic_parity(y_group, i)\n",
    "        \n",
    "        DP_results[i].append(FPR)\n",
    "        \n",
    "    plt.plot(n_clusters, DP_results, label=f\"Groupe {i}\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Demographic Parity\")\n",
    "plt.title(\"Demographic Parity vs. Number of Clusters\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 4.1] Fairness of your model </b>  <br>\n",
    "    You considered two different measures for the fairness of your model and checked for various variants of your algorithm (number of clusters) the value of these fairness metrics.\n",
    "\n",
    "Is your algorithm unfair ? If yes, which ethnic group is penalized by the unfairness of your model ?\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>[Question 4.2] Presence of the sensitive features in the dataset [BONUS]</b> <br> \n",
    "In Cell 1.5, you removed the sensitive features from your dataset before building your algorithm. Yet, you may have noticed unfairness in your algorithm.\n",
    "\n",
    "1. Provide reasons why it is not necessarily enough to remove sensitive features from your dataset if you want to have fair predictions.\n",
    "2. Compute FPR and Demographic Parity for your algorithm when trained on the full dataset. Is the fairness of your classifier worse ?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for the BONUS question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font size=7 color=#009999> <b>PART 5 - Visualization </b> </font> <br><br>\n",
    "\n",
    "<font size=5 color=#009999> <b>5.1 Visualize your results</b> <br>\n",
    "</font>\n",
    "In the last cell, you can create the figure of your choice to visualize your results. You can be as creative as you want as long as you only use one figure (with potentially more than one plot).\n",
    "\n",
    "You will be evaluated on the clarity of your figure. You should ask yourself the following question while creating it: \"Is the message I am trying to convey clear enough so that a student from another group can take a quick look and understand it directly ?\" If the answer is positive, it's probably a great plot !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for the VISUALIZATION question."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
